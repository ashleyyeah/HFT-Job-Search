# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nZoW8qujUFKKzwemIBiozSm-DDA5Vtk2
"""

import requests
import bs4
from bs4 import BeautifulSoup
import pandas as pd
import time

import csv
list_of_skills = []
with open('skills.csv', newline='') as csvfile:
     spamreader = csv.reader(csvfile)
     for row in spamreader:
         row = row[1].lower()
         list_of_skills.append(row)
list_of_skills.pop(0)
list_of_skills

import requests
from bs4 import BeautifulSoup
import pandas as pd

list_of_companies = []
for i in range(1,30):
  url = 'https://www.indeed.com/jobs?q=quantitative%20trader&start='+str(i)+'0&vjk=7378394c893f9bfc'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  
  for div in soup.find_all(name="div", attrs={"class":"job_seen_beacon"}):
        for a in div.find_all(name="span", attrs={"class":"companyName"}):
          list_of_companies.append(a.get_text())
list_of_companies = set(list_of_companies)
list_of_companies = list(list_of_companies)
print(list_of_companies)
print(len(list_of_companies))

for ind, comp in enumerate(list_of_companies):
  list_of_companies[ind] = comp.upper()
dataframe_of_companies = pd.DataFrame(list_of_companies).to_csv("companies.csv")

company_group_1 = list_of_companies[0:1]
company_group_2 = list_of_companies[5:9]
company_group_3 = list_of_skills[10:14]
company_group_4 = list_of_skills[15:19]
company_group_5 = list_of_skills[20:24]
company_group_6 = list_of_skills[25:29]
company_group_7 = list_of_skills[30:34]
company_group_8 = list_of_skills[35:39]
company_group_9 = list_of_skills[40:44]

import requests
from bs4 import BeautifulSoup
import pandas as pd

big_list_overall = []
for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[1:2]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[2:3]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[3:4]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[4:5]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[5:6]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[6:7]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[7:8]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[8:9]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[9:10]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[10:11]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[11:12]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[12:13]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[13:14]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[14:15]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[15:16]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[16:17]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[17:18]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[18:19]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[19:20]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[20:21]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[21:22]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[22:23]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[23:24]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[24:25]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[25:26]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[26:27]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[27:28]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[28:29]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[29:30]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[30:31]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[31:32]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[32:33]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[33:34]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[34:35]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[35:36]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[36:37]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[37:38]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[38:39]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[39:40]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[40:41]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[41:42]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[42:43]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[43:44]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[44:45]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[45:46]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[46:47]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[47:48]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[48:49]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[49:50]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[50:51]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[51:52]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[52:53]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[53:54]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[54:55]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[55:56]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[56:57]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[57:58]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[58:59]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[59:60]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[60:61]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[61:62]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[62:63]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[63:64]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[64:65]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[65:66]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[66:67]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[67:68]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[68:69]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[69:70]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[70:71]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[71:72]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[72:73]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[73:74]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[74:75]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[75:76]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[76:77]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[77:78]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[78:79]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[79:80]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[80:81]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[81:82]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[82:83]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[83:84]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[84:85]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[85:86]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[86:87]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[87:88]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[88:89]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[89:90]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[90:91]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[91:92]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[92:93]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[93:94]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[94:95]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[95:96]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[96:97]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[97:98]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[98:99]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[99:100]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[100:101]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[101:102]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[102:103]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[103:104]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[104:105]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[105:106]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[106:107]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[107:108]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[108:109]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[109:110]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[110:111]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[111:112]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[112:113]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[113:114]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[114:115]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[115:116]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[116:117]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[117:118]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[118:119]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[119:120]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[120:121]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[121:122]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[122:123]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[123:124]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[124:125]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[125:126]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[126:127]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[127:128]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[128:129]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[129:130]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[130:131]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[131:132]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[132:133]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[133:134]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[134:135]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[135:136]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[136:137]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[137:138]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

data_whole = pd.DataFrame(big_list_overall).to_csv("all_columns.csv")

company_group_1 = list_of_companies[138:139]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[139:140]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[140:141]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[141:142]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[142:143]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[143:144]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[144:145]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[145:146]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[146:147]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[147:148]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[148:149]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[149:150]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[150:151]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[151:152]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[152:153]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[153:154]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[155:156]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[156:157]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[157:158]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[158:159]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[159:160]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[160:161]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[161:162]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[162:163]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[163:164]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[164:165]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[165:166]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[166:167]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[167:168]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[168:169]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[169:170]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[170:171]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[171:172]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[172:173]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[173:174]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)

company_group_1 = list_of_companies[174:175]

for company in company_group_1:
  if len(company)==1:
    url = "https://www.indeed.com/jobs?q=" + company+ "&l&vjk=ffb30c714e385e7e"
  elif len(company)>=2:
    company_ = company.split(" ")
    url = "https://www.indeed.com/jobs?q=" 
    for i in company_:
      url = url+ i+"%20"
    url = url +"&l&vjk=ffb30c714e385e7e"
  #print(url)
  jobdesc_url = 'https://www.indeed.ae/rpc/jobdescs'
  soup = BeautifulSoup(requests.get(url).content, 'html.parser')
  jks = ','.join(jk['data-jk'] for jk in soup.select('[data-jk]'))
  
  descriptions = requests.get(jobdesc_url, params={'jks': jks}).json()
  
  for jk in soup.select('[data-jk]'):
    #print(jk)
    one_column = []
    one_column_skills = []
    #print(jk)
    #if jk.find("h2") !=-1:
      # print(jk.find("h2"))
      #print(jk.h2.get_text(strip=True))
    # if jk.h2 == None:
    #     break
      # print(type(jk.h2))
      # print(type(5))
    #print(jk.h2.get_text(strip=True))
    one_column.append(company)
    print(jk.h2.get_text(strip=True))
    one_column.append(jk.h2.get_text(strip=True))
    print(one_column)
      # for a in soup.find_all(name="span", attrs={"class":"companyName"}):
      # one_column.append(jk.span.get_text(strip=True))
      # print(jk.span[1].get_text(strip=True))
      #print()
      #print(jk.find_next('span', class_='company').get_text(strip=True))
      #print(BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text())
    # if jk not in descriptions:
    #     continue
      #print("reach")
    string_ = BeautifulSoup(descriptions[jk['data-jk']], 'html.parser').get_text()
    string_ = string_.lower()
    #print(string_)
    for i in list_of_skills:
      if string_.find(i) !=-1:
        one_column_skills.append(i)
    one_column.append(one_column_skills)
    #print(one_column_skills)
    big_list_overall.append(one_column)
print(big_list_overall)